Object
Classification in
Urban Aerial
Drone Footage

Jack, Aidan, Liam
Project Recap

Objective:
Create a computer vision object classification model to identify objects in
aerial drone videos
Prior Research:
Stanford Drone Dataset

Our dataset:
VisDrone Dataset
 -   300 videos, ~260,000 frames of urban Chinese cities
Baseline Model


● PyTorch Torchvision Faster R-CNN
   ○ Object detection model pre-trained on COCO
   ○ 330,000+ images and wider variety of locations
   ○ Includes same VisDrone classes (Pedestrian, Car, etc…)
● Simple CNN model
   ○ Small # of parameters (2-3 layers, no drop-off or
     optimizations, etc)
    Our Model Architecture


    Transfer Learning:                   Region Proposal Network              Region of Interest (ROI)
                                                   (RPN):                             Head:
●   Load pretrained ResNet-50
    or -101 model with FPN               ●   Use built-in RPN layers to       ●   Customize ROI detection
    (better suited for drone                 generate regions                     box head layers with
    images)                              ●   Anchor box tuning as                 dropout regularization
●   Freeze or allow fine-tuning              needed (e.g. smaller sizes)      ●   Add final box predictor,
●   Remove original detection                                                     specified for VisDrone data
    layers (head)



                                          Training Optimizations:
                     ●    Data augmentation
                     ●    Optimizers (SGD with momentum, L2 regularization)
                     ●    Learning rate scheduling
                     ●    Early stopping
Evaluation Criteria


Modeled off VisDrone’s official competition criteria:

 -   Average Precision: “quality”
      - Precision = TP / (TP + FP)
      - Measures the accuracy of classifications and precision of
         bounding boxes
      - Intersection over Union (the closeness of two bounding boxes)
 -   Average Recall: “quantity”
      - Recall = TP / (TP + FN)
      - Measures the model’s ability to find all the relevant objects in an
         image
             Notes from Presentation

-   Check out interest over union (IOU) later for differing image sizes
-   Should be using YOLO or R-CNN model for object detection
      - Check literature of other drone deep learning projects to see what they use
      - If not using one of these in final project, should be good explanation why not
-   Try minimizing complexity at beginning by only attempting to detect one class
      - Potentially use one hot encoding for multiple classes training
      - Test with negative examples too (where boxes have nothing on purpose)
