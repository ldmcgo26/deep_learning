{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Assignment Description\n",
    "\n",
    "Please upload the following materials to the GitHub repository of your project work and submit the URL again:\n",
    "\n",
    "- Python code that downloads, prepares and loads the data (this was the task of Milestone 1, now you have only to adjust it to the other parts of your code)\n",
    "- Python code for the baseline model.\n",
    "- Python code that trains a deep learning model,\n",
    "- Python code that evaluates the results on a (separate) test set,\n",
    "- Updated README.MD file with instructions how to run the code.\n",
    "\n",
    "Please add as much comments to your code as much is needed to be able to easily understand it.\n",
    "\n",
    "At this stage, it is not required to have good (or even reasonable) results, the only requirement is to have the data loading-preparation-training-evaluation pipeline ready."
   ],
   "id": "c3f2ead7c38810b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Our Model Architecture\n",
    "\n",
    "### 1. Transfer Learning:\n",
    "- Load pre-trained ResNet-50 or -101 model with FPN (better suited for drone images)\n",
    "- Freeze or allow fine-tuning\n",
    "- Remove original detection layers (head)\n",
    "\n",
    "### 2. Region Proposal Network (RPN):\n",
    "- Use built-in RPN layers to generate regions\n",
    "- Anchor box tuning as needed (e.g. smaller sizes)\n",
    "\n",
    "### 3. Region of Interest (ROI) Head:\n",
    "- Customize ROI detection box head layers with dropout regularization\n",
    "- Add final box predictor, specified for VisDrone data\n",
    "\n",
    "### 4. Misc. Training Optimizations:\n",
    "- Data augmentation\n",
    "- Optimizers (SGD with momentum, L2 regularization)\n",
    "- Learning rate scheduling\n",
    "- Early stopping"
   ],
   "id": "23cce9be47f32da9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T06:52:55.767827Z",
     "start_time": "2025-04-24T06:52:49.354435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "#\n",
    "# PyTorch and related libraries for deep learning\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Computer vision and image processing libraries\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Model-specific imports for Faster R-CNN\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "\n",
    "# Visualization and utility libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#print(f\"Using device: {device}\")\n"
   ],
   "id": "fa4fb773622185fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:03:24.613101Z",
     "start_time": "2025-04-24T00:03:24.502986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Loading and Preparation (adapted from MS1)\n",
    "\"\"\"\n",
    "This section reuses code from Milestone 1 to download, prepare, and load the VisDrone dataset.\n",
    "The dataset consists of drone images with object annotations for 11 classes.\n",
    "\"\"\"\n",
    "\n",
    "#--------------------------\n",
    "# Dataset Directory Setup\n",
    "#--------------------------\n",
    "# Define paths for dataset\n",
    "dataset_dir = \"/content/VisDrone\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "#--------------------------\n",
    "# Download Functions\n",
    "#--------------------------\n",
    "# Function to download and extract training data\n",
    "def download_train_data():\n",
    "    \"\"\"\n",
    "    Downloads and extracts the VisDrone training dataset.\n",
    "    Uses gdown to fetch from Google Drive and unzip to the dataset directory.\n",
    "    \"\"\"\n",
    "    file_id = '1a2oHjcEcwXP8oUF95qiwrqzACb2YlUhn'\n",
    "    output = f'{dataset_dir}/VisDrone2019-DET-train.zip'\n",
    "\n",
    "    !gdown --id {file_id} -O {output}\n",
    "    !unzip -q {output} -d {dataset_dir}\n",
    "\n",
    "# Function to download and extract validation data\n",
    "def download_val_data():\n",
    "    \"\"\"\n",
    "    Downloads and extracts the VisDrone validation dataset.\n",
    "    Uses gdown to fetch from Google Drive and unzip to the dataset directory.\n",
    "    \"\"\"\n",
    "    file_id = '1bxK5zgLn0_L8x276eKkuYA_FzwCIjb59'\n",
    "    output = f'{dataset_dir}/VisDrone2019-DET-val.zip'\n",
    "\n",
    "    !gdown --id {file_id} -O {output}\n",
    "    !unzip -q {output} -d {dataset_dir}\n",
    "\n",
    "# Function to download and extract test data\n",
    "def download_test_data():\n",
    "    \"\"\"\n",
    "    Downloads and extracts the VisDrone test dataset.\n",
    "    Uses gdown to fetch from Google Drive and unzip to the dataset directory.\n",
    "    \"\"\"\n",
    "    subfolder = \"VisDrone2019-DET-test-dev\"\n",
    "    output_zip = f\"{dataset_dir}/{subfolder}.zip\"\n",
    "    extract_path = f\"{dataset_dir}/{subfolder}\"\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "    file_id = '1PFdW_VFSCfZ_sTSZAGjQdifF_Xd5mf0V'\n",
    "\n",
    "    !gdown --id {file_id} -O {output_zip}\n",
    "    !unzip -q {output_zip} -d {extract_path}\n",
    "\n",
    "# Uncomment to download data\n",
    "# download_train_data()\n",
    "# download_val_data()\n",
    "# download_test_data()\n",
    "\n",
    "#--------------------------\n",
    "# Data Augmentation Classes\n",
    "#--------------------------\n",
    "# These classes implement data augmentation techniques for object detection\n",
    "# Each class follows the same interface: __init__ for parameters and __call__ for transformation\n",
    "\n",
    "# Compose class to apply multiple transformations sequentially\n",
    "class Compose:\n",
    "    \"\"\"\n",
    "    Composes several transforms together.\n",
    "\n",
    "    Args:\n",
    "        transforms (list): List of transforms to compose.\n",
    "    \"\"\"\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "# Random horizontal flip augmentation\n",
    "class RandomHorizontalFlip:\n",
    "    \"\"\"\n",
    "    Randomly flips the image and its bounding boxes horizontally.\n",
    "\n",
    "    Args:\n",
    "        prob (float): Probability of flipping the image.\n",
    "    \"\"\"\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < self.prob:\n",
    "            height, width = image.shape[-2:]\n",
    "            image = image.flip(-1)\n",
    "\n",
    "            # Flip boxes: x_min becomes (width - x_max) and x_max becomes (width - x_min)\n",
    "            boxes = target[\"boxes\"]\n",
    "            boxes[:, [0, 2]] = width - boxes[:, [2, 0]]\n",
    "            target[\"boxes\"] = boxes\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# Random brightness adjustment augmentation\n",
    "class RandomBrightness:\n",
    "    \"\"\"\n",
    "    Randomly adjusts the brightness of the image.\n",
    "\n",
    "    Args:\n",
    "        brightness (float): Maximum brightness adjustment factor.\n",
    "    \"\"\"\n",
    "    def __init__(self, brightness=0.2):\n",
    "        self.brightness = brightness\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < 0.5:\n",
    "            # Calculate a random brightness factor within the specified range\n",
    "            brightness_factor = random.uniform(max(0, 1 - self.brightness), 1 + self.brightness)\n",
    "            image = torchvision.transforms.functional.adjust_brightness(image, brightness_factor)\n",
    "        return image, target\n",
    "\n",
    "# Random contrast adjustment augmentation\n",
    "class RandomContrast:\n",
    "    \"\"\"\n",
    "    Randomly adjusts the contrast of the image.\n",
    "\n",
    "    Args:\n",
    "        contrast (float): Maximum contrast adjustment factor.\n",
    "    \"\"\"\n",
    "    def __init__(self, contrast=0.2):\n",
    "        self.contrast = contrast\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < 0.5:\n",
    "            # Calculate a random contrast factor within the specified range\n",
    "            contrast_factor = random.uniform(max(0, 1 - self.contrast), 1 + self.contrast)\n",
    "            image = torchvision.transforms.functional.adjust_contrast(image, contrast_factor)\n",
    "        return image, target\n",
    "\n",
    "#--------------------------\n",
    "# VisDrone Dataset Class\n",
    "#--------------------------\n",
    "# Custom PyTorch Dataset class for the VisDrone dataset\n",
    "class VisDroneDataset(Dataset):\n",
    "    \"\"\"\n",
    "    VisDrone dataset class for object detection.\n",
    "\n",
    "    This class handles loading images and annotations, resizing, \n",
    "    converting to tensors, and applying data augmentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, images_np, annotations_np, resize_to=(640, 640), transforms=None, device='cpu', augment=False):\n",
    "        \"\"\"\n",
    "        Initialize the VisDrone dataset.\n",
    "\n",
    "        Args:\n",
    "            images_np (list): List of numpy arrays containing images\n",
    "            annotations_np (list): List of dictionaries containing annotations (boxes and labels)\n",
    "            resize_to (tuple): Tuple of (height, width) to resize images to\n",
    "            transforms (callable, optional): Optional transforms to apply to images and annotations\n",
    "            device (str): Device to load tensors to ('cpu' or 'cuda')\n",
    "            augment (bool): Whether to apply data augmentation (only for training)\n",
    "        \"\"\"\n",
    "        self.images = images_np\n",
    "        self.annotations = annotations_np\n",
    "        self.resize_to = resize_to\n",
    "        self.transforms = transforms\n",
    "        self.device = device\n",
    "        self.augment = augment\n",
    "\n",
    "        # Set up data augmentation pipeline if augmentation is enabled\n",
    "        if self.augment:\n",
    "            self.data_augmentation = Compose([\n",
    "                RandomHorizontalFlip(0.5),\n",
    "                RandomBrightness(0.2),\n",
    "                RandomContrast(0.2)\n",
    "            ])\n",
    "        else:\n",
    "            self.data_augmentation = None\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of images in the dataset.\"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to get\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is a dictionary containing boxes and labels\n",
    "        \"\"\"\n",
    "        # Get the image and annotation at the specified index\n",
    "        image = self.images[idx]\n",
    "        ann = self.annotations[idx]\n",
    "\n",
    "        # Get original image dimensions\n",
    "        orig_h, orig_w = image.shape[:2]\n",
    "\n",
    "        #--------------------------\n",
    "        # Image Preprocessing\n",
    "        #--------------------------\n",
    "        # Resize image to the target size\n",
    "        resized_image = cv2.resize(image, (self.resize_to[1], self.resize_to[0]))\n",
    "\n",
    "        # Convert to PyTorch tensor and normalize to [0, 1]\n",
    "        # Change from HWC to CHW format (height, width, channels) -> (channels, height, width)\n",
    "        resized_image = torch.from_numpy(resized_image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        #--------------------------\n",
    "        # Bounding Box Preprocessing\n",
    "        #--------------------------\n",
    "        # Calculate scaling factors for bounding boxes\n",
    "        scale_x = self.resize_to[1] / orig_w\n",
    "        scale_y = self.resize_to[0] / orig_h\n",
    "\n",
    "        # Scale bounding boxes to match the resized image\n",
    "        boxes = ann['boxes'].copy()\n",
    "        boxes[:, [0, 2]] = boxes[:, [0, 2]] * scale_x  # Scale x coordinates\n",
    "        boxes[:, [1, 3]] = boxes[:, [1, 3]] * scale_y  # Scale y coordinates\n",
    "\n",
    "        # Get class labels\n",
    "        labels = ann['labels'].copy()\n",
    "\n",
    "        #--------------------------\n",
    "        # Convert to PyTorch Tensors\n",
    "        #--------------------------\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        # Create target dictionary with boxes, labels, and image_id\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([idx])\n",
    "        }\n",
    "\n",
    "        #--------------------------\n",
    "        # Apply Transformations\n",
    "        #--------------------------\n",
    "        # Apply data augmentation if specified\n",
    "        if self.augment and self.data_augmentation:\n",
    "            resized_image, target = self.data_augmentation(resized_image, target)\n",
    "\n",
    "        # Apply additional transforms if specified\n",
    "        if self.transforms:\n",
    "            resized_image, target = self.transforms(resized_image, target)\n",
    "\n",
    "        # Move tensors to the specified device\n",
    "        return resized_image.to(self.device), target\n",
    "\n",
    "#--------------------------\n",
    "# Data Loading and Processing\n",
    "#--------------------------\n",
    "def load_and_process_data(dataset_dir, subset, max_samples=None, include_negative=False):\n",
    "    \"\"\"\n",
    "    Load and process VisDrone data from disk.\n",
    "\n",
    "    This function reads images and their corresponding annotation files,\n",
    "    processes the annotations into bounding boxes and class labels,\n",
    "    and optionally includes images with no valid annotations.\n",
    "\n",
    "    Args:\n",
    "        dataset_dir (str): Directory containing the dataset\n",
    "        subset (str): 'train', 'val', or 'test'\n",
    "        max_samples (int, optional): Maximum number of samples to load (for testing)\n",
    "        include_negative (bool): Whether to include images with no valid annotations (negative examples)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (images_np, annotations_np) where:\n",
    "            - images_np is a list of numpy arrays containing images\n",
    "            - annotations_np is a list of dictionaries containing annotations\n",
    "    \"\"\"\n",
    "    #--------------------------\n",
    "    # Set up paths based on subset\n",
    "    #--------------------------\n",
    "    if subset == 'train':\n",
    "        data_path = os.path.join(dataset_dir, \"VisDrone2019-DET-train\")\n",
    "    elif subset == 'val':\n",
    "        data_path = os.path.join(dataset_dir, \"VisDrone2019-DET-val\")\n",
    "    elif subset == 'test':\n",
    "        data_path = os.path.join(dataset_dir, \"VisDrone2019-DET-test-dev\")\n",
    "    else:\n",
    "        raise ValueError(\"subset must be 'train', 'val', or 'test'\")\n",
    "\n",
    "    # Define paths to images and annotations\n",
    "    image_dir = os.path.join(data_path, \"images\")\n",
    "    ann_dir = os.path.join(data_path, \"annotations\")\n",
    "\n",
    "    #--------------------------\n",
    "    # Get list of image files\n",
    "    #--------------------------\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    if max_samples:\n",
    "        # Limit the number of samples if specified\n",
    "        image_files = image_files[:max_samples]\n",
    "\n",
    "    #--------------------------\n",
    "    # Process images and annotations\n",
    "    #--------------------------\n",
    "    images_np = []\n",
    "    annotations_np = []\n",
    "    negative_count = 0\n",
    "\n",
    "    for img_file in image_files:\n",
    "        # Load image\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "\n",
    "        # Load corresponding annotation file\n",
    "        ann_file = img_file.replace('.jpg', '.txt')\n",
    "        ann_path = os.path.join(ann_dir, ann_file)\n",
    "\n",
    "        # Parse annotation file\n",
    "        boxes = []\n",
    "        classes = []\n",
    "\n",
    "        with open(ann_path, 'r') as f:\n",
    "            for line in f:\n",
    "                # VisDrone annotation format: <x, y, width, height, score, class, truncation, occlusion>\n",
    "                x, y, w, h, score, obj_class, trunc, occ = map(int, line.strip().split(','))\n",
    "\n",
    "                # Skip ignored regions (class 0)\n",
    "                if obj_class != 0:\n",
    "                    # Convert from [x, y, width, height] to [x1, y1, x2, y2] format\n",
    "                    boxes.append([x, y, x + w, y + h])\n",
    "                    classes.append(obj_class)\n",
    "\n",
    "        #--------------------------\n",
    "        # Handle negative examples\n",
    "        #--------------------------\n",
    "        # Include images with no valid annotations if specified\n",
    "        if len(boxes) > 0 or include_negative:\n",
    "            if len(boxes) == 0:\n",
    "                # This is a negative example (image with no valid annotations)\n",
    "                negative_count += 1\n",
    "                # For negative examples, we still need to provide empty arrays\n",
    "                boxes_array = np.zeros((0, 4), dtype=np.float32)\n",
    "                classes_array = np.zeros((0,), dtype=np.int32)\n",
    "            else:\n",
    "                # Convert lists to numpy arrays\n",
    "                boxes_array = np.array(boxes, dtype=np.float32)\n",
    "                classes_array = np.array(classes, dtype=np.int32)\n",
    "\n",
    "            # Add image and annotations to the lists\n",
    "            images_np.append(img)\n",
    "            annotations_np.append({\n",
    "                'boxes': boxes_array,\n",
    "                'labels': classes_array\n",
    "            })\n",
    "\n",
    "    #--------------------------\n",
    "    # Print summary\n",
    "    #--------------------------\n",
    "    if include_negative:\n",
    "        print(f\"Loaded {len(images_np)} {subset} images ({negative_count} negative examples)\")\n",
    "    else:\n",
    "        print(f\"Loaded {len(images_np)} {subset} images with valid annotations\")\n",
    "\n",
    "    return images_np, annotations_np\n",
    "\n",
    "#--------------------------\n",
    "# DataLoader Creation\n",
    "#--------------------------\n",
    "def create_dataloaders(images_np_train, annotations_np_train, \n",
    "                       images_np_val, annotations_np_val, \n",
    "                       images_np_test, annotations_np_test,\n",
    "                       batch_size=4, augment_train=True):\n",
    "    \"\"\"\n",
    "    Create PyTorch dataloaders for train, validation, and test sets.\n",
    "\n",
    "    This function creates dataset objects for each split and wraps them in DataLoader\n",
    "    objects that handle batching, shuffling, and collation.\n",
    "\n",
    "    Args:\n",
    "        images_np_train (list): List of training images as numpy arrays\n",
    "        annotations_np_train (list): List of training annotations as dictionaries\n",
    "        images_np_val (list): List of validation images as numpy arrays\n",
    "        annotations_np_val (list): List of validation annotations as dictionaries\n",
    "        images_np_test (list): List of test images as numpy arrays\n",
    "        annotations_np_test (list): List of test annotations as dictionaries\n",
    "        batch_size (int): Batch size for dataloaders\n",
    "        augment_train (bool): Whether to apply data augmentation to the training set\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, valid_loader, test_loader) - DataLoader objects for each split\n",
    "    \"\"\"\n",
    "    #--------------------------\n",
    "    # Create Dataset Objects\n",
    "    #--------------------------\n",
    "    # Training dataset with optional data augmentation\n",
    "    train_dataset = VisDroneDataset(\n",
    "        images_np_train, \n",
    "        annotations_np_train, \n",
    "        transforms=None,  # No additional transforms beyond augmentation\n",
    "        augment=augment_train  # Apply data augmentation only to training set\n",
    "    )\n",
    "\n",
    "    # Validation dataset (no augmentation)\n",
    "    val_dataset = VisDroneDataset(\n",
    "        images_np_val, \n",
    "        annotations_np_val, \n",
    "        transforms=None, \n",
    "        augment=False\n",
    "    )\n",
    "\n",
    "    # Test dataset (no augmentation)\n",
    "    test_dataset = VisDroneDataset(\n",
    "        images_np_test, \n",
    "        annotations_np_test, \n",
    "        transforms=None, \n",
    "        augment=False\n",
    "    )\n",
    "\n",
    "    #--------------------------\n",
    "    # Create DataLoader Objects\n",
    "    #--------------------------\n",
    "    # Training dataloader with shuffling\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,  # Shuffle training data for better generalization\n",
    "        collate_fn=lambda x: tuple(zip(*x))  # Custom collate function for object detection\n",
    "    )\n",
    "\n",
    "    # Validation dataloader (no shuffling)\n",
    "    valid_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        collate_fn=lambda x: tuple(zip(*x))\n",
    "    )\n",
    "\n",
    "    # Test dataloader (no shuffling)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        collate_fn=lambda x: tuple(zip(*x))\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "# For demonstration, load a small subset of data\n",
    "# In practice, you would load the full dataset\n",
    "# images_np_train, annotations_np_train = load_and_process_data(dataset_dir, 'train', max_samples=100)\n",
    "# images_np_val, annotations_np_val = load_and_process_data(dataset_dir, 'val', max_samples=50)\n",
    "# images_np_test, annotations_np_test = load_and_process_data(dataset_dir, 'test', max_samples=50)\n",
    "\n",
    "# train_loader, valid_loader, test_loader = create_dataloaders(\n",
    "#     images_np_train, annotations_np_train,\n",
    "#     images_np_val, annotations_np_val,\n",
    "#     images_np_test, annotations_np_test,\n",
    "#     batch_size=4\n",
    "# )\n"
   ],
   "id": "c279e2594e0fac0d",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/content'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOSError\u001B[39m                                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# Define paths for dataset\u001B[39;00m\n\u001B[32m      8\u001B[39m dataset_dir = \u001B[33m\"\u001B[39m\u001B[33m/content/VisDrone\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43mos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# Download training set\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdownload_train_data\u001B[39m():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen os>:215\u001B[39m, in \u001B[36mmakedirs\u001B[39m\u001B[34m(name, mode, exist_ok)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen os>:225\u001B[39m, in \u001B[36mmakedirs\u001B[39m\u001B[34m(name, mode, exist_ok)\u001B[39m\n",
      "\u001B[31mOSError\u001B[39m: [Errno 30] Read-only file system: '/content'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#--------------------------\n",
    "# Baseline Model Implementation\n",
    "#--------------------------\n",
    "\"\"\"\n",
    "This section implements a simple baseline model for object detection.\n",
    "We use a pre-trained Faster R-CNN with ResNet-50 backbone from torchvision.\n",
    "\"\"\"\n",
    "\n",
    "def get_baseline_model(num_classes):\n",
    "    \"\"\"\n",
    "    Create a baseline Faster R-CNN model with ResNet-50 backbone.\n",
    "\n",
    "    This function loads a pre-trained Faster R-CNN model and adapts it for our\n",
    "    specific number of classes by replacing the classifier head.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of classes to predict (including background)\n",
    "                          For VisDrone, this is 12 (11 object classes + background)\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: Baseline Faster R-CNN model ready for fine-tuning\n",
    "    \"\"\"\n",
    "    #--------------------------\n",
    "    # Load Pre-trained Model\n",
    "    #--------------------------\n",
    "    # Load pre-trained Faster R-CNN model with ResNet-50 backbone and Feature Pyramid Network (FPN)\n",
    "    # The model is pre-trained on COCO dataset which has similar object categories\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    #--------------------------\n",
    "    # Replace Classifier Head\n",
    "    #--------------------------\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # Replace the classifier with a new one for our specific number of classes\n",
    "    # FastRCNNPredictor handles both classification and bounding box regression\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n"
   ],
   "id": "d2e8d78553095644"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#--------------------------\n",
    "# Custom Deep Learning Model Implementation\n",
    "#--------------------------\n",
    "\"\"\"\n",
    "This section implements our custom deep learning model based on the architecture description.\n",
    "We use a pre-trained ResNet-50 or ResNet-101 with FPN as the backbone,\n",
    "customize the RPN and ROI head, and add training optimizations.\n",
    "\"\"\"\n",
    "\n",
    "def get_custom_model(num_classes, backbone_name='resnet50', trainable_backbone_layers=3):\n",
    "    \"\"\"\n",
    "    Create a custom Faster R-CNN model with ResNet+FPN backbone.\n",
    "\n",
    "    This function builds a custom object detection model with several improvements:\n",
    "    1. Transfer Learning: Uses pre-trained ResNet with FPN backbone\n",
    "    2. Region Proposal Network: Customized anchor sizes for small objects in drone imagery\n",
    "    3. ROI Head: Added dropout regularization to prevent overfitting\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of classes to predict (including background)\n",
    "        backbone_name (str): Name of the backbone ('resnet50' or 'resnet101')\n",
    "        trainable_backbone_layers (int): Number of backbone layers to train (others will be frozen)\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: Custom Faster R-CNN model\n",
    "    \"\"\"\n",
    "    #--------------------------\n",
    "    # 1. Transfer Learning: Backbone\n",
    "    #--------------------------\n",
    "    # Load pre-trained ResNet with Feature Pyramid Network (FPN)\n",
    "    # FPN is particularly useful for detecting objects at different scales\n",
    "    backbone = resnet_fpn_backbone(\n",
    "        backbone_name=backbone_name,  # ResNet-50 or ResNet-101\n",
    "        pretrained=True,              # Use pre-trained weights from ImageNet\n",
    "        trainable_layers=trainable_backbone_layers  # Number of layers to fine-tune\n",
    "    )\n",
    "\n",
    "    #--------------------------\n",
    "    # 2. Region Proposal Network (RPN)\n",
    "    #--------------------------\n",
    "    # Customize anchor sizes for drone imagery\n",
    "    # Drone images often contain small objects viewed from above, so we use smaller anchor sizes\n",
    "    anchor_generator = AnchorGenerator(\n",
    "        sizes=((16, 32, 64, 128, 256),),  # Smaller anchor sizes than default\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),)  # Standard aspect ratios\n",
    "    )\n",
    "\n",
    "    #--------------------------\n",
    "    # Create the Faster R-CNN model\n",
    "    #--------------------------\n",
    "    model = FasterRCNN(\n",
    "        backbone=backbone,\n",
    "        num_classes=num_classes,\n",
    "        rpn_anchor_generator=anchor_generator,\n",
    "        # Increase RPN proposals for better small object detection\n",
    "        rpn_pre_nms_top_n_train=2000,   # Number of proposals before NMS during training\n",
    "        rpn_pre_nms_top_n_test=1000,    # Number of proposals before NMS during testing\n",
    "        rpn_post_nms_top_n_train=1000,  # Number of proposals after NMS during training\n",
    "        rpn_post_nms_top_n_test=500,    # Number of proposals after NMS during testing\n",
    "    )\n",
    "\n",
    "    #--------------------------\n",
    "    # 3. ROI Head Customization\n",
    "    #--------------------------\n",
    "    # Replace the default box predictor with a custom one that includes dropout regularization\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # Define a custom box predictor class with dropout\n",
    "    class CustomFastRCNNPredictor(nn.Module):\n",
    "        \"\"\"\n",
    "        Custom Fast R-CNN predictor with dropout regularization.\n",
    "\n",
    "        This predictor adds dropout before the final classification and regression layers\n",
    "        to reduce overfitting, which is important for the limited drone dataset.\n",
    "        \"\"\"\n",
    "        def __init__(self, in_channels, num_classes, dropout_prob=0.3):\n",
    "            super(CustomFastRCNNPredictor, self).__init__()\n",
    "            self.dropout = nn.Dropout(p=dropout_prob)  # Dropout layer\n",
    "            self.cls_score = nn.Linear(in_channels, num_classes)  # Classification layer\n",
    "            self.bbox_pred = nn.Linear(in_channels, num_classes * 4)  # Bounding box regression layer\n",
    "\n",
    "        def forward(self, x):\n",
    "            \"\"\"Forward pass through the predictor.\"\"\"\n",
    "            x = self.dropout(x)  # Apply dropout\n",
    "            cls_scores = self.cls_score(x)  # Predict class scores\n",
    "            bbox_preds = self.bbox_pred(x)  # Predict bounding box coordinates\n",
    "            return cls_scores, bbox_preds\n",
    "\n",
    "    # Replace the default box predictor with our custom one\n",
    "    model.roi_heads.box_predictor = CustomFastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n"
   ],
   "id": "afc71b91cd5983ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#--------------------------\n",
    "# Training Function\n",
    "#--------------------------\n",
    "\"\"\"\n",
    "This section implements the training function for our models.\n",
    "It includes training optimizations like SGD with momentum, L2 regularization,\n",
    "learning rate scheduling, and early stopping.\n",
    "\"\"\"\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, num_epochs=10, lr=0.005, device=device):\n",
    "    \"\"\"\n",
    "    Train the object detection model with optimizations.\n",
    "\n",
    "    This function handles the complete training process including:\n",
    "    - Moving the model to the specified device\n",
    "    - Setting up optimizer with momentum and L2 regularization\n",
    "    - Implementing learning rate scheduling\n",
    "    - Training for the specified number of epochs\n",
    "    - Validating after each epoch\n",
    "    - Implementing early stopping\n",
    "    - Saving and loading the best model\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Model to train\n",
    "        train_loader (DataLoader): DataLoader for training data\n",
    "        valid_loader (DataLoader): DataLoader for validation data\n",
    "        num_epochs (int): Number of epochs to train for\n",
    "        lr (float): Initial learning rate\n",
    "        device (torch.device): Device to train on ('cpu' or 'cuda')\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, train_loss_history, val_loss_history)\n",
    "            - model: Trained model (best version based on validation loss)\n",
    "            - train_loss_history: List of training losses per epoch\n",
    "            - val_loss_history: List of validation losses per epoch\n",
    "    \"\"\"\n",
    "    #--------------------------\n",
    "    # Setup and Initialization\n",
    "    #--------------------------\n",
    "    # Move model to the specified device (GPU or CPU)\n",
    "    model.to(device)\n",
    "\n",
    "    # Set up optimizer: SGD with momentum and L2 regularization\n",
    "    # Only optimize parameters that require gradients\n",
    "    optimizer = optim.SGD(\n",
    "        [p for p in model.parameters() if p.requires_grad], \n",
    "        lr=lr,                # Initial learning rate\n",
    "        momentum=0.9,         # Momentum factor for SGD\n",
    "        weight_decay=0.0005   # L2 regularization to prevent overfitting\n",
    "    )\n",
    "\n",
    "    # Set up learning rate scheduler to reduce LR when training plateaus\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, \n",
    "        step_size=3,  # Decrease learning rate every 3 epochs\n",
    "        gamma=0.1     # Multiply learning rate by 0.1 (reduce by 90%)\n",
    "    )\n",
    "\n",
    "    # Early stopping parameters to prevent overfitting\n",
    "    patience = 3                    # Number of epochs to wait for improvement\n",
    "    best_val_loss = float('inf')    # Initialize best validation loss\n",
    "    early_stop_counter = 0          # Counter for early stopping\n",
    "\n",
    "    # Initialize lists to track training and validation loss history\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    #--------------------------\n",
    "    # Training Loop\n",
    "    #--------------------------\n",
    "    for epoch in range(num_epochs):\n",
    "        #--------------------------\n",
    "        # Training Phase\n",
    "        #--------------------------\n",
    "        model.train()  # Set model to training mode\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Iterate through batches in the training dataloader\n",
    "        for images, targets in train_loader:\n",
    "            # Move data to the specified device\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Zero gradients before forward pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass - Faster R-CNN returns a dict of losses when targets are provided\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            # Sum all losses (classification, regression, etc.)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate batch loss\n",
    "            epoch_loss += losses.item()\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "\n",
    "        #--------------------------\n",
    "        # Validation Phase\n",
    "        #--------------------------\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0\n",
    "\n",
    "        # No gradient calculation needed for validation\n",
    "        with torch.no_grad():\n",
    "            for images, targets in valid_loader:\n",
    "                # Move data to the specified device\n",
    "                images = [image.to(device) for image in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                # Forward pass\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                val_loss += losses.item()\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        avg_val_loss = val_loss / len(valid_loader)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "\n",
    "        # Update learning rate according to the scheduler\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        #--------------------------\n",
    "        # Epoch Summary\n",
    "        #--------------------------\n",
    "        # Calculate and print epoch statistics\n",
    "        time_elapsed = time.time() - start_time\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, '\n",
    "              f'Val Loss: {avg_val_loss:.4f}, '\n",
    "              f'Time: {time_elapsed:.2f}s')\n",
    "\n",
    "        #--------------------------\n",
    "        # Early Stopping Check\n",
    "        #--------------------------\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            # If validation loss improved, save the model\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            early_stop_counter = 0  # Reset counter\n",
    "        else:\n",
    "            # If validation loss didn't improve, increment counter\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break  # Stop training if no improvement for 'patience' epochs\n",
    "\n",
    "    #--------------------------\n",
    "    # Finalization\n",
    "    #--------------------------\n",
    "    # Load the best model (lowest validation loss)\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "    return model, train_loss_history, val_loss_history\n"
   ],
   "id": "eff5cb90c523c64b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#--------------------------\n",
    "# Evaluation Metrics and Functions\n",
    "#--------------------------\n",
    "\"\"\"\n",
    "This section implements evaluation metrics and functions for our models.\n",
    "It includes IoU calculation, Average Precision, Average Recall, and mAP.\n",
    "\"\"\"\n",
    "\n",
    "#--------------------------\n",
    "# IoU Calculation\n",
    "#--------------------------\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "\n",
    "    IoU is a measure of the overlap between two bounding boxes, calculated as\n",
    "    the area of intersection divided by the area of union. It ranges from 0\n",
    "    (no overlap) to 1 (perfect overlap).\n",
    "\n",
    "    Args:\n",
    "        box1 (array-like): First box in format [x1, y1, x2, y2]\n",
    "                          where (x1, y1) is the top-left corner and\n",
    "                          (x2, y2) is the bottom-right corner\n",
    "        box2 (array-like): Second box in same format as box1\n",
    "\n",
    "    Returns:\n",
    "        float: IoU value between 0 and 1\n",
    "    \"\"\"\n",
    "    #--------------------------\n",
    "    # Find Intersection Coordinates\n",
    "    #--------------------------\n",
    "    # Get the coordinates of the intersection rectangle\n",
    "    # The intersection rectangle is formed by the maximum of the top-left coordinates\n",
    "    # and the minimum of the bottom-right coordinates\n",
    "    x1 = max(box1[0], box2[0])  # Max of left coordinates\n",
    "    y1 = max(box1[1], box2[1])  # Max of top coordinates\n",
    "    x2 = min(box1[2], box2[2])  # Min of right coordinates\n",
    "    y2 = min(box1[3], box2[3])  # Min of bottom coordinates\n",
    "\n",
    "    #--------------------------\n",
    "    # Calculate Intersection Area\n",
    "    #--------------------------\n",
    "    # If there's no overlap, width or height will be negative\n",
    "    width = max(0, x2 - x1)   # Width of intersection\n",
    "    height = max(0, y2 - y1)  # Height of intersection\n",
    "    intersection = width * height  # Area of intersection\n",
    "\n",
    "    #--------------------------\n",
    "    # Calculate Union Area\n",
    "    #--------------------------\n",
    "    # Calculate area of both boxes\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])  # Width * Height of box1\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])  # Width * Height of box2\n",
    "\n",
    "    # Union = Sum of areas - Intersection\n",
    "    union = box1_area + box2_area - intersection\n",
    "\n",
    "    #--------------------------\n",
    "    # Calculate IoU\n",
    "    #--------------------------\n",
    "    # Handle edge case where union is 0\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "\n",
    "    return iou\n",
    "\n",
    "#--------------------------\n",
    "# Precision and Recall Calculation\n",
    "#--------------------------\n",
    "def calculate_precision_recall(pred_boxes, pred_labels, pred_scores, gt_boxes, gt_labels, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and Average Precision (AP) for a single image.\n",
    "\n",
    "    This function evaluates object detection performance by comparing predicted\n",
    "    bounding boxes with ground truth boxes. It calculates precision (how many\n",
    "    detected objects are correct) and recall (how many actual objects are detected),\n",
    "    as well as Average Precision which summarizes the precision-recall curve.\n",
    "\n",
    "    Args:\n",
    "        pred_boxes (numpy.ndarray): Predicted bounding boxes in format [x1, y1, x2, y2]\n",
    "        pred_labels (numpy.ndarray): Predicted class labels\n",
    "        pred_scores (numpy.ndarray): Predicted confidence scores\n",
    "        gt_boxes (numpy.ndarray): Ground truth bounding boxes in format [x1, y1, x2, y2]\n",
    "        gt_labels (numpy.ndarray): Ground truth class labels\n",
    "        iou_threshold (float): IoU threshold for considering a detection as correct (true positive)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (precision, recall, ap)\n",
    "            - precision (numpy.ndarray): Precision values at different detection thresholds\n",
    "            - recall (numpy.ndarray): Recall values at different detection thresholds\n",
    "            - ap (float): Average Precision value\n",
    "    \"\"\"\n",
    "    #--------------------------\n",
    "    # Sort Predictions by Confidence\n",
    "    #--------------------------\n",
    "    # Sort predictions by score (highest confidence first)\n",
    "    sorted_indices = np.argsort(-pred_scores)\n",
    "    pred_boxes = pred_boxes[sorted_indices]\n",
    "    pred_labels = pred_labels[sorted_indices]\n",
    "    pred_scores = pred_scores[sorted_indices]\n",
    "\n",
    "    #--------------------------\n",
    "    # Initialize Evaluation Arrays\n",
    "    #--------------------------\n",
    "    # Arrays to track true positives and false positives for each prediction\n",
    "    tp = np.zeros(len(pred_boxes))  # True positives\n",
    "    fp = np.zeros(len(pred_boxes))  # False positives\n",
    "\n",
    "    # Track which ground truth boxes have been matched to avoid double-counting\n",
    "    gt_matched = np.zeros(len(gt_boxes))\n",
    "\n",
    "    #--------------------------\n",
    "    # Evaluate Each Prediction\n",
    "    #--------------------------\n",
    "    # For each predicted box (in order of decreasing confidence)\n",
    "    for i, (pred_box, pred_label) in enumerate(zip(pred_boxes, pred_labels)):\n",
    "        # Find ground truth boxes with the same class label\n",
    "        same_label_indices = np.where(gt_labels == pred_label)[0]\n",
    "\n",
    "        # If there are no ground truth boxes with this label, it's a false positive\n",
    "        if len(same_label_indices) == 0:\n",
    "            fp[i] = 1\n",
    "            continue\n",
    "\n",
    "        #--------------------------\n",
    "        # Find Best Matching Ground Truth Box\n",
    "        #--------------------------\n",
    "        max_iou = -np.inf  # Initialize maximum IoU\n",
    "        max_idx = -1       # Initialize index of best matching ground truth box\n",
    "\n",
    "        # Check each ground truth box with the same label\n",
    "        for idx in same_label_indices:\n",
    "            # Skip already matched ground truth boxes\n",
    "            if gt_matched[idx]:\n",
    "                continue\n",
    "\n",
    "            # Calculate IoU between prediction and this ground truth box\n",
    "            iou = calculate_iou(pred_box, gt_boxes[idx])\n",
    "\n",
    "            # Update if this is the best match so far\n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                max_idx = idx\n",
    "\n",
    "        #--------------------------\n",
    "        # Determine True/False Positive\n",
    "        #--------------------------\n",
    "        # If the best match has IoU above threshold, count as true positive\n",
    "        if max_iou >= iou_threshold and max_idx >= 0:\n",
    "            tp[i] = 1  # Mark as true positive\n",
    "            gt_matched[max_idx] = 1  # Mark this ground truth as matched\n",
    "        else:\n",
    "            fp[i] = 1  # Mark as false positive\n",
    "\n",
    "    #--------------------------\n",
    "    # Calculate Precision and Recall\n",
    "    #--------------------------\n",
    "    # Calculate cumulative true positives and false positives\n",
    "    cum_tp = np.cumsum(tp)  # Cumulative true positives\n",
    "    cum_fp = np.cumsum(fp)  # Cumulative false positives\n",
    "\n",
    "    # Calculate precision: TP / (TP + FP)\n",
    "    precision = cum_tp / (cum_tp + cum_fp)\n",
    "\n",
    "    # Calculate recall: TP / Total ground truth\n",
    "    # Handle case where there are no ground truth boxes\n",
    "    recall = cum_tp / len(gt_boxes) if len(gt_boxes) > 0 else np.zeros_like(cum_tp)\n",
    "\n",
    "    #--------------------------\n",
    "    # Calculate Average Precision\n",
    "    #--------------------------\n",
    "    # Use 11-point interpolation method (standard in object detection)\n",
    "    ap = 0\n",
    "    for t in np.arange(0, 1.1, 0.1):  # 11 points from 0 to 1\n",
    "        if np.sum(recall >= t) == 0:\n",
    "            p = 0  # No recall at this threshold\n",
    "        else:\n",
    "            # Maximum precision at recalls >= t\n",
    "            p = np.max(precision[recall >= t])\n",
    "        ap += p / 11  # Average over 11 points\n",
    "\n",
    "    return precision, recall, ap\n",
    "\n",
    "#--------------------------\n",
    "# Mean Average Precision (mAP) Calculation\n",
    "#--------------------------\n",
    "def calculate_map(all_pred_boxes, all_pred_labels, all_pred_scores, all_gt_boxes, all_gt_labels, num_classes, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate mean Average Precision (mAP) across all classes.\n",
    "\n",
    "    mAP is the standard evaluation metric for object detection. It calculates the Average\n",
    "    Precision (AP) for each class separately and then averages them to get the mAP.\n",
    "    This function processes predictions and ground truths across multiple images.\n",
    "\n",
    "    Args:\n",
    "        all_pred_boxes (list): List of arrays of predicted bounding boxes for each image\n",
    "        all_pred_labels (list): List of arrays of predicted class labels for each image\n",
    "        all_pred_scores (list): List of arrays of predicted confidence scores for each image\n",
    "        all_gt_boxes (list): List of arrays of ground truth bounding boxes for each image\n",
    "        all_gt_labels (list): List of arrays of ground truth class labels for each image\n",
    "        num_classes (int): Number of classes (including background)\n",
    "        iou_threshold (float): IoU threshold for considering a detection as correct\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ap_per_class, mAP)\n",
    "            - ap_per_class (numpy.ndarray): Average Precision for each class\n",
    "            - mAP (float): Mean Average Precision across all classes\n",
    "    \"\"\"\n",
    "    #--------------------------\n",
    "    # Initialize Results Array\n",
    "    #--------------------------\n",
    "    # Array to store Average Precision for each class\n",
    "    ap_per_class = np.zeros(num_classes)\n",
    "\n",
    "    #--------------------------\n",
    "    # Process Each Class\n",
    "    #--------------------------\n",
    "    # Skip background class (index 0) and calculate AP for each object class\n",
    "    for c in range(1, num_classes):\n",
    "        #--------------------------\n",
    "        # Collect Class-Specific Predictions and Ground Truths\n",
    "        #--------------------------\n",
    "        # Lists to store predictions and ground truths for this class across all images\n",
    "        class_pred_boxes = []\n",
    "        class_pred_scores = []\n",
    "        class_gt_boxes = []\n",
    "\n",
    "        # Process each image\n",
    "        for i in range(len(all_pred_boxes)):\n",
    "            # Get predictions for this class in this image\n",
    "            class_mask = all_pred_labels[i] == c\n",
    "            class_pred_boxes.append(all_pred_boxes[i][class_mask])\n",
    "            class_pred_scores.append(all_pred_scores[i][class_mask])\n",
    "\n",
    "            # Get ground truths for this class in this image\n",
    "            class_gt_mask = all_gt_labels[i] == c\n",
    "            class_gt_boxes.append(all_gt_boxes[i][class_gt_mask])\n",
    "\n",
    "        #--------------------------\n",
    "        # Skip Classes with No Ground Truth\n",
    "        #--------------------------\n",
    "        # If there are no ground truth boxes for this class, AP is 0\n",
    "        if sum(len(boxes) for boxes in class_gt_boxes) == 0:\n",
    "            ap_per_class[c] = 0\n",
    "            continue\n",
    "\n",
    "        #--------------------------\n",
    "        # Prepare Data for AP Calculation\n",
    "        #--------------------------\n",
    "        # Concatenate predictions and ground truths from all images\n",
    "        all_class_pred_boxes = np.concatenate(class_pred_boxes) if class_pred_boxes else np.array([])\n",
    "        all_class_pred_scores = np.concatenate(class_pred_scores) if class_pred_scores else np.array([])\n",
    "        all_class_gt_boxes = np.concatenate(class_gt_boxes) if class_gt_boxes else np.array([])\n",
    "\n",
    "        # Sort predictions by confidence score (highest first)\n",
    "        sorted_indices = np.argsort(-all_class_pred_scores)\n",
    "        all_class_pred_boxes = all_class_pred_boxes[sorted_indices]\n",
    "        all_class_pred_scores = all_class_pred_scores[sorted_indices]\n",
    "\n",
    "        #--------------------------\n",
    "        # Evaluate Predictions\n",
    "        #--------------------------\n",
    "        # Arrays to track true positives and false positives\n",
    "        tp = np.zeros(len(all_class_pred_boxes))\n",
    "        fp = np.zeros(len(all_class_pred_boxes))\n",
    "\n",
    "        # For each predicted box\n",
    "        for i, pred_box in enumerate(all_class_pred_boxes):\n",
    "            # Find the ground truth box with the highest IoU\n",
    "            max_iou = -np.inf\n",
    "            max_idx = -1\n",
    "\n",
    "            for j, gt_box in enumerate(all_class_gt_boxes):\n",
    "                iou = calculate_iou(pred_box, gt_box)\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    max_idx = j\n",
    "\n",
    "            # Determine if prediction is a true positive or false positive\n",
    "            if max_iou >= iou_threshold:\n",
    "                tp[i] = 1  # True positive\n",
    "            else:\n",
    "                fp[i] = 1  # False positive\n",
    "\n",
    "        #--------------------------\n",
    "        # Calculate Precision and Recall\n",
    "        #--------------------------\n",
    "        # Calculate cumulative true positives and false positives\n",
    "        cum_tp = np.cumsum(tp)\n",
    "        cum_fp = np.cumsum(fp)\n",
    "\n",
    "        # Calculate precision and recall at each detection threshold\n",
    "        precision = cum_tp / (cum_tp + cum_fp)\n",
    "        recall = cum_tp / len(all_class_gt_boxes)\n",
    "\n",
    "        #--------------------------\n",
    "        # Calculate Average Precision\n",
    "        #--------------------------\n",
    "        # Use 11-point interpolation method (standard in object detection)\n",
    "        ap = 0\n",
    "        for t in np.arange(0, 1.1, 0.1):  # 11 points from 0 to 1\n",
    "            if np.sum(recall >= t) == 0:\n",
    "                p = 0  # No recall at this threshold\n",
    "            else:\n",
    "                # Maximum precision at recalls >= t\n",
    "                p = np.max(precision[recall >= t])\n",
    "            ap += p / 11  # Average over 11 points\n",
    "\n",
    "        # Store AP for this class\n",
    "        ap_per_class[c] = ap\n",
    "\n",
    "    #--------------------------\n",
    "    # Calculate Mean Average Precision\n",
    "    #--------------------------\n",
    "    # Average the AP values across all classes (excluding background)\n",
    "    mAP = np.mean(ap_per_class[1:])\n",
    "\n",
    "    return ap_per_class, mAP\n",
    "\n",
    "#--------------------------\n",
    "# Model Evaluation Function\n",
    "#--------------------------\n",
    "\"\"\"\n",
    "This section implements the evaluation function for our models.\n",
    "It calculates metrics like mAP (mean Average Precision) on the test set\n",
    "and visualizes predictions compared to ground truth.\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_model(model, test_loader, device=device):\n",
    "    \"\"\"\n",
    "    Evaluate the object detection model on the test set.\n",
    "\n",
    "    This function performs a comprehensive evaluation of the model by:\n",
    "    1. Calculating test loss\n",
    "    2. Computing mAP (mean Average Precision) across all classes\n",
    "    3. Visualizing predictions vs ground truth\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Model to evaluate\n",
    "        test_loader (DataLoader): DataLoader for test data\n",
    "        device (torch.device): Device to evaluate on ('cpu' or 'cuda')\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation results:\n",
    "            - test_loss: Average loss on test set\n",
    "            - mAP: Mean Average Precision\n",
    "            - ap_per_class: Average Precision for each class\n",
    "    \"\"\"\n",
    "    #--------------------------\n",
    "    # Setup\n",
    "    #--------------------------\n",
    "    # Move model to the specified device and set to evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize test loss\n",
    "    test_loss = 0\n",
    "\n",
    "    #--------------------------\n",
    "    # Collect Predictions and Ground Truths\n",
    "    #--------------------------\n",
    "    # Lists to store predictions and ground truths for mAP calculation\n",
    "    all_pred_boxes = []    # Predicted bounding boxes\n",
    "    all_pred_labels = []   # Predicted class labels\n",
    "    all_pred_scores = []   # Predicted confidence scores\n",
    "    all_gt_boxes = []      # Ground truth bounding boxes\n",
    "    all_gt_labels = []     # Ground truth class labels\n",
    "\n",
    "    # Disable gradient calculation for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Iterate through batches in the test dataloader\n",
    "        for images, targets in test_loader:\n",
    "            # Move data to the specified device\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            #--------------------------\n",
    "            # Calculate Test Loss\n",
    "            #--------------------------\n",
    "            # Forward pass with targets to get loss\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            test_loss += losses.item()\n",
    "\n",
    "            #--------------------------\n",
    "            # Get Model Predictions\n",
    "            #--------------------------\n",
    "            # Forward pass without targets to get predictions\n",
    "            predictions = model(images)\n",
    "\n",
    "            # Convert predictions and targets to CPU for evaluation\n",
    "            predictions = [{k: v.cpu() for k, v in p.items()} for p in predictions]\n",
    "            targets = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
    "\n",
    "            #--------------------------\n",
    "            # Process Each Image in Batch\n",
    "            #--------------------------\n",
    "            # Store predictions and ground truths for mAP calculation\n",
    "            for pred, target in zip(predictions, targets):\n",
    "                # Filter predictions with confidence score > 0.5\n",
    "                mask = pred['scores'] > 0.5\n",
    "                pred_boxes = pred['boxes'][mask].numpy()\n",
    "                pred_labels = pred['labels'][mask].numpy()\n",
    "                pred_scores = pred['scores'][mask].numpy()\n",
    "\n",
    "                # Get ground truths\n",
    "                gt_boxes = target['boxes'].numpy()\n",
    "                gt_labels = target['labels'].numpy()\n",
    "\n",
    "                # Add to collection lists\n",
    "                all_pred_boxes.append(pred_boxes)\n",
    "                all_pred_labels.append(pred_labels)\n",
    "                all_pred_scores.append(pred_scores)\n",
    "                all_gt_boxes.append(gt_boxes)\n",
    "                all_gt_labels.append(gt_labels)\n",
    "\n",
    "    #--------------------------\n",
    "    # Calculate Metrics\n",
    "    #--------------------------\n",
    "    # Calculate average test loss\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "    # Define class names for reporting\n",
    "    class_names = {\n",
    "        1: 'Pedestrian',\n",
    "        2: 'Person',\n",
    "        3: 'Car',\n",
    "        4: 'Van',\n",
    "        5: 'Bus',\n",
    "        6: 'Truck',\n",
    "        7: 'Motor',\n",
    "        8: 'Bicycle',\n",
    "        9: 'Awning-tricycle',\n",
    "        10: 'Tricycle',\n",
    "        11: 'Other'\n",
    "    }\n",
    "\n",
    "    #--------------------------\n",
    "    # Calculate mAP\n",
    "    #--------------------------\n",
    "    # Number of classes (11 object classes + background)\n",
    "    num_classes = 12\n",
    "\n",
    "    # Calculate Average Precision for each class and mean AP\n",
    "    ap_per_class, mAP = calculate_map(\n",
    "        all_pred_boxes, all_pred_labels, all_pred_scores,\n",
    "        all_gt_boxes, all_gt_labels, num_classes\n",
    "    )\n",
    "\n",
    "    # Print mAP\n",
    "    print(f'mAP: {mAP:.4f}')\n",
    "\n",
    "    # Print AP for each class\n",
    "    print(\"Average Precision per class:\")\n",
    "    for c in range(1, num_classes):\n",
    "        print(f'{class_names[c]}: {ap_per_class[c]:.4f}')\n",
    "\n",
    "    #--------------------------\n",
    "    # Visualize Predictions\n",
    "    #--------------------------\n",
    "    # Get a batch of images for visualization\n",
    "    model.eval()\n",
    "    images, targets = next(iter(test_loader))\n",
    "    images = [img.to(device) for img in images]\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images)\n",
    "\n",
    "    # Convert to CPU for visualization\n",
    "    images = [img.cpu() for img in images]\n",
    "    predictions = [{k: v.cpu() for k, v in p.items()} for p in predictions]\n",
    "    targets = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
    "\n",
    "    #--------------------------\n",
    "    # Prepare Visualization Data\n",
    "    #--------------------------\n",
    "    # Use the first image in the batch for visualization\n",
    "    image = images[0].permute(1, 2, 0).numpy()  # Convert from CHW to HWC format\n",
    "\n",
    "    # Get predictions for the first image\n",
    "    pred_boxes = predictions[0]['boxes'].numpy()\n",
    "    pred_scores = predictions[0]['scores'].numpy()\n",
    "    pred_labels = predictions[0]['labels'].numpy()\n",
    "\n",
    "    # Get ground truths for the first image\n",
    "    gt_boxes = targets[0]['boxes'].numpy()\n",
    "    gt_labels = targets[0]['labels'].numpy()\n",
    "\n",
    "    # Filter predictions with confidence score > 0.5\n",
    "    mask = pred_scores > 0.5\n",
    "    pred_boxes = pred_boxes[mask]\n",
    "    pred_labels = pred_labels[mask]\n",
    "    pred_scores = pred_scores[mask]\n",
    "\n",
    "    #--------------------------\n",
    "    # Calculate IoU for Visualization\n",
    "    #--------------------------\n",
    "    # Calculate IoU between each prediction and the best matching ground truth\n",
    "    ious = []\n",
    "    for pred_box in pred_boxes:\n",
    "        max_iou = 0\n",
    "        for gt_box in gt_boxes:\n",
    "            iou = calculate_iou(pred_box, gt_box)\n",
    "            max_iou = max(max_iou, iou)\n",
    "        ious.append(max_iou)\n",
    "\n",
    "    #--------------------------\n",
    "    # Create Visualization\n",
    "    #--------------------------\n",
    "    # Create figure for visualization\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # Draw ground truth boxes (green)\n",
    "    for box, label in zip(gt_boxes, gt_labels):\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), x2-x1, y2-y1, \n",
    "            linewidth=2, \n",
    "            edgecolor='g', \n",
    "            facecolor='none'\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "\n",
    "        # Add label text\n",
    "        class_name = class_names.get(label.item(), f'Class {label.item()}')\n",
    "        plt.text(\n",
    "            x1, y1-5, \n",
    "            f'GT: {class_name}', \n",
    "            color='white', \n",
    "            bbox=dict(facecolor='green', alpha=0.5)\n",
    "        )\n",
    "\n",
    "    # Draw predicted boxes (red)\n",
    "    for box, label, score, iou in zip(pred_boxes, pred_labels, pred_scores, ious):\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), x2-x1, y2-y1, \n",
    "            linewidth=2, \n",
    "            edgecolor='r', \n",
    "            facecolor='none'\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "\n",
    "        # Add label text with confidence score and IoU\n",
    "        class_name = class_names.get(label.item(), f'Class {label.item()}')\n",
    "        plt.text(\n",
    "            x1, y1+15, \n",
    "            f'Pred: {class_name}: {score:.2f}, IoU: {iou:.2f}', \n",
    "            color='white', \n",
    "            bbox=dict(facecolor='red', alpha=0.5)\n",
    "        )\n",
    "\n",
    "    # Finalize visualization\n",
    "    plt.axis('off')\n",
    "    plt.title('Model Predictions vs Ground Truth')\n",
    "    plt.show()\n",
    "\n",
    "    #--------------------------\n",
    "    # Return Results\n",
    "    #--------------------------\n",
    "    return {\n",
    "        'test_loss': avg_test_loss,\n",
    "        'mAP': mAP,\n",
    "        'ap_per_class': ap_per_class\n",
    "    }\n"
   ],
   "id": "728e3c4226abaf8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#--------------------------\n",
    "# Main Execution\n",
    "#--------------------------\n",
    "\"\"\"\n",
    "This section demonstrates how to use the functions defined above to:\n",
    "1. Load and prepare the data\n",
    "2. Create and train the baseline model\n",
    "3. Create and train the custom model\n",
    "4. Evaluate both models on the test set\n",
    "5. Compare results and visualize performance\n",
    "\"\"\"\n",
    "\n",
    "# Example usage (commented out to avoid execution)\n",
    "\"\"\"\n",
    "#--------------------------\n",
    "# 1. Data Loading and Preparation\n",
    "#--------------------------\n",
    "# Load training data with negative examples (images with no objects)\n",
    "# Negative examples help the model learn to distinguish between objects and background\n",
    "images_np_train, annotations_np_train = load_and_process_data(\n",
    "    dataset_dir=dataset_dir,\n",
    "    subset='train',\n",
    "    max_samples=100,              # Limit samples for faster execution (remove for full training)\n",
    "    include_negative=True         # Include images with no valid annotations\n",
    ")\n",
    "\n",
    "# Load validation data (no negative examples needed)\n",
    "images_np_val, annotations_np_val = load_and_process_data(\n",
    "    dataset_dir=dataset_dir,\n",
    "    subset='val',\n",
    "    max_samples=50,               # Limit samples for faster execution\n",
    "    include_negative=False\n",
    ")\n",
    "\n",
    "# Load test data (no negative examples needed)\n",
    "images_np_test, annotations_np_test = load_and_process_data(\n",
    "    dataset_dir=dataset_dir,\n",
    "    subset='test',\n",
    "    max_samples=50,               # Limit samples for faster execution\n",
    "    include_negative=False\n",
    ")\n",
    "\n",
    "#--------------------------\n",
    "# Create DataLoaders\n",
    "#--------------------------\n",
    "# Create dataloaders with data augmentation for the training set\n",
    "train_loader, valid_loader, test_loader = create_dataloaders(\n",
    "    images_np_train=images_np_train,\n",
    "    annotations_np_train=annotations_np_train,\n",
    "    images_np_val=images_np_val,\n",
    "    annotations_np_val=annotations_np_val,\n",
    "    images_np_test=images_np_test,\n",
    "    annotations_np_test=annotations_np_test,\n",
    "    batch_size=4,                 # Adjust based on available GPU memory\n",
    "    augment_train=True            # Apply data augmentation to the training set\n",
    ")\n",
    "\n",
    "#--------------------------\n",
    "# 2. Baseline Model Training\n",
    "#--------------------------\n",
    "# Define number of classes (11 object classes + background)\n",
    "num_classes = 12\n",
    "\n",
    "# Create baseline model (pre-trained Faster R-CNN with ResNet-50)\n",
    "baseline_model = get_baseline_model(num_classes)\n",
    "\n",
    "# Train baseline model\n",
    "baseline_model, baseline_train_loss, baseline_val_loss = train_model(\n",
    "    model=baseline_model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    num_epochs=5,                 # Train for 5 epochs\n",
    "    lr=0.005                      # Initial learning rate\n",
    ")\n",
    "\n",
    "#--------------------------\n",
    "# 3. Custom Model Training\n",
    "#--------------------------\n",
    "# Create custom model with improved architecture\n",
    "custom_model = get_custom_model(\n",
    "    num_classes=num_classes,\n",
    "    backbone_name='resnet50',     # Can also try 'resnet101' for potentially better results\n",
    "    trainable_backbone_layers=3   # Number of backbone layers to fine-tune\n",
    ")\n",
    "\n",
    "# Train custom model\n",
    "custom_model, custom_train_loss, custom_val_loss = train_model(\n",
    "    model=custom_model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    num_epochs=10,                # Train for more epochs than baseline\n",
    "    lr=0.005                      # Initial learning rate\n",
    ")\n",
    "\n",
    "#--------------------------\n",
    "# 4. Model Evaluation\n",
    "#--------------------------\n",
    "# Evaluate baseline model on test set\n",
    "baseline_results = evaluate_model(\n",
    "    model=baseline_model,\n",
    "    test_loader=test_loader\n",
    ")\n",
    "\n",
    "# Evaluate custom model on test set\n",
    "custom_results = evaluate_model(\n",
    "    model=custom_model,\n",
    "    test_loader=test_loader\n",
    ")\n",
    "\n",
    "#--------------------------\n",
    "# 5. Results Comparison\n",
    "#--------------------------\n",
    "# Print overall metrics\n",
    "print(\"Baseline model test loss:\", baseline_results['test_loss'])\n",
    "print(\"Baseline model mAP:\", baseline_results['mAP'])\n",
    "print(\"Custom model test loss:\", custom_results['test_loss'])\n",
    "print(\"Custom model mAP:\", custom_results['mAP'])\n",
    "\n",
    "# Define class names for reporting\n",
    "class_names = {\n",
    "    1: 'Pedestrian',\n",
    "    2: 'Person',\n",
    "    3: 'Car',\n",
    "    4: 'Van',\n",
    "    5: 'Bus',\n",
    "    6: 'Truck',\n",
    "    7: 'Motor',\n",
    "    8: 'Bicycle',\n",
    "    9: 'Awning-tricycle',\n",
    "    10: 'Tricycle',\n",
    "    11: 'Other'\n",
    "}\n",
    "\n",
    "# Compare Average Precision per class\n",
    "print(\"\\nAverage Precision per class comparison:\")\n",
    "print(\"Class\\t\\tBaseline AP\\tCustom AP\\tImprovement\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Print AP for each class and the improvement\n",
    "for c in range(1, num_classes):\n",
    "    class_name = class_names[c]\n",
    "    baseline_ap = baseline_results['ap_per_class'][c]\n",
    "    custom_ap = custom_results['ap_per_class'][c]\n",
    "    improvement = custom_ap - baseline_ap\n",
    "    print(f\"{class_name:<15}\\t{baseline_ap:.4f}\\t\\t{custom_ap:.4f}\\t\\t{improvement:+.4f}\")\n",
    "\n",
    "#--------------------------\n",
    "# 6. Visualization\n",
    "#--------------------------\n",
    "# Plot training and validation loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Baseline model loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(baseline_train_loss, label='Train Loss')\n",
    "plt.plot(baseline_val_loss, label='Val Loss')\n",
    "plt.title('Baseline Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Custom model loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(custom_train_loss, label='Train Loss')\n",
    "plt.plot(custom_val_loss, label='Val Loss')\n",
    "plt.title('Custom Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ],
   "id": "7d0cac37ab312d32"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
